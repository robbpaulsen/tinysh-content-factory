# YouTube Shorts Factory

Automated YouTube Shorts generation from Reddit stories using AI. Transform stories into engaging videos with generated images, voiceovers, captions, and background music.

## Features

- ü§ñ **AI-Powered Content**: Uses Google Gemini to create motivational speeches from Reddit stories
- üé® **Image Generation**: FLUX (via Together.ai) creates cinematic images for each scene
- üó£Ô∏è **Text-to-Speech**: Local TTS using Kokoro or Chatterbox with voice cloning
- üé¨ **Video Processing**: Automatic captioning, merging, and background music
- üìä **Google Sheets Integration**: Store and manage stories
- üì§ **YouTube Upload**: Automatic upload with metadata
- üîÑ **Complete Pipeline**: Reddit ‚Üí AI ‚Üí Video ‚Üí YouTube

## Architecture

This project replaces the original n8n workflow with a clean Python implementation:

```
Reddit Stories ‚Üí Google Sheets ‚Üí Gemini (script) ‚Üí Loop per scene:
  ‚îú‚îÄ FLUX (image generation)
  ‚îú‚îÄ Kokoro/Chatterbox (TTS)
  ‚îî‚îÄ Local server (video + captions)
‚Üí Merge all videos ‚Üí Add music ‚Üí Upload to YouTube
```

## Prerequisites

### Required Services

1. **Local Media Server**: Running on `http://localhost:8000` (or configure your own)
   - Handles TTS generation (Kokoro/Chatterbox)
   - Video processing with FFmpeg
   - Caption generation
   - File storage

2. **API Keys**:
   - Google Gemini API key
   - Together.ai API key
   - Google OAuth credentials (for Sheets & YouTube)
   - Reddit (no API keys needed - uses public endpoints)

### System Requirements

- Python 3.11+
- `uv` package manager
- Media server with:
  - FFmpeg
  - Kokoro TTS or Chatterbox TTS
  - 4+ CPU cores, 8GB+ RAM recommended

## Installation

### 1. Install uv

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

### 2. Clone and Setup

```bash
git clone <your-repo>
cd n8n-to-python-transpiler

# Initialize project with uv
uv venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
uv pip install -e .
```

### 3. Configuration

```bash
# Create .env file
python -m src.main init

# Edit .env with your credentials
nano .env  # or use your preferred editor
```

### 4. Google OAuth Setup

1. Go to [Google Cloud Console](https://console.cloud.google.com/)
2. Create a project (or use existing)
3. Enable APIs:
   - Google Sheets API
   - YouTube Data API v3
4. Create OAuth 2.0 credentials (Desktop app)
5. Download `credentials.json` and place in project root

### 5. API Keys

- **Gemini**: Get from [Google AI Studio](https://makersuite.google.com/app/apikey)
- **Together.ai**: Sign up at [Together.ai](https://together.ai/)

## Usage

### Validate Configuration

```bash
python -m src.main validate-config
```

### Check Media Server

```bash
python -m src.main check-server
```

### Update Stories from Reddit

```bash
# Fetch 25 stories from configured subreddit
python -m src.main update-stories

# Custom subreddit and limit
python -m src.main update-stories --subreddit getdisciplined --limit 50
```

### Generate Videos

```bash
# Generate 1 video from Google Sheets
python -m src.main generate --count 1

# Generate 3 videos and update stories first
python -m src.main generate --count 3 --update
```

### Generate from Single Story

```bash
# Use Reddit post ID
python -m src.main generate-single abc123xyz
```

## Configuration Options

Key settings in `.env`:

### Content Generation

```bash
SUBREDDIT=selfimprovement
CONTENT_TYPE="motivational speech"
ART_STYLE="Create a cinematic image..."  # Full prompt in .env.example
```

### Voice & Music Profiles

The system uses **profiles** to manage voice and music configurations, defined in `profiles.yaml`:

```bash
# Optional: Override default profile from profiles.yaml
ACTIVE_PROFILE=frank_motivational

# Optional: Path to profiles configuration
PROFILES_PATH=profiles.yaml
```

**Profile Configuration (`profiles.yaml`):**

Each profile includes:
- **Voice settings**: TTS engine (Kokoro/Chatterbox), voice samples, parameters
- **Music playlist**: Multiple tracks with rotation (random/sequential)
- **Volume settings**: Per-profile music volume

Example profile structure:

```yaml
profiles:
  frank_motivational:
    name: "Frank - Motivational"
    description: "Energetic, inspiring tone"
    voice:
      engine: chatterbox
      sample_path: "D:/Music/voces/frank/sample.mp3"
      temperature: 0.7
      cfg_weight: 0.65
      exaggeration: 0.55
    music:
      playlist:
        - path: "D:/Music/tracks/track1.mp3"
          name: "Track Name"
      volume: 0.1
      rotation: random  # or sequential

default_profile: frank_motivational
```

**Using Profiles via CLI:**

```bash
# Use default profile
python -m src.main generate --count 1

# Use specific profile
python -m src.main generate --count 1 --profile brody_calm

# Generate single story with profile
python -m src.main generate-single abc123 --profile denzel_powerful
```

**Benefits:**
- ‚úÖ Easy switching between voice styles
- ‚úÖ Music rotation (avoid repetition)
- ‚úÖ Multiple profiles for different content types
- ‚úÖ Path validation for voice samples and music files

### Image Generation

```bash
FLUX_MODEL=black-forest-labs/FLUX.1-schnell-Free
IMAGE_WIDTH=768
IMAGE_HEIGHT=1344
```


### Performance Optimization

```bash
# FFmpeg encoder settings (configured on media server)
FFMPEG_ENCODER=auto     # Options: auto, nvenc (GPU), x264 (CPU)
FFMPEG_PRESET=p4        # NVENC: p1-p7, x264: ultrafast/fast/medium
FFMPEG_CQ=23            # Quality: 18=best, 28=worst
FFMPEG_BITRATE=5M       # Target bitrate for videos
FFMPEG_AUDIO_BITRATE=128k
```

**Performance Results:**
- ‚ö° **GPU Encoding (NVENC)**: 5-10x faster than CPU encoding with NVIDIA GPU
- ‚ö° **Sequential Mode**: ~3 minutes per video (model stays loaded)
- ‚ö° **Individual Mode**: 5-7 minutes (model loads/unloads each time)
- ‚ö° **Token-Optimized Prompts**: 15-45 second videos (480-1440 tokens)

### SEO Optimization

The system automatically generates SEO-optimized YouTube metadata using Google Gemini:

```bash
# Enable/disable SEO metadata generation (default: enabled)
SEO_ENABLED=true
```

**What it generates:**
- üìù **Optimized Titles**: 50-60 characters, clickable, keyword-rich
- üìã **Smart Descriptions**: Strategic keywords, hashtags, CTAs
- üè∑Ô∏è **Relevant Tags**: 10-15 tags per video for discoverability
- üéØ **Category Selection**: Automatic YouTube category assignment
- üé® **Profile-Aware**: Adapts to your active voice/music profile

**Output:**

Each video generates two files:
```
output/
‚îú‚îÄ‚îÄ video_001.mp4              # Generated video
‚îî‚îÄ‚îÄ video_001_metadata.json    # SEO metadata
```

**Metadata JSON format:**
```json
{
  "title": "5 Habits That Changed My Life Forever",
  "description": "Discover powerful habits...\n\n#motivation #shorts #selfimprovement",
  "tags": ["motivation", "self improvement", "productivity", ...],
  "category_id": "22",
  "original_title": "Transform Your Life",
  "original_description": "A story about...",
  "profile": "frank_motivational"
}
```

**Benefits:**
- ‚úÖ Saves time: No manual title/description writing
- ‚úÖ Consistency: Professional metadata for every video
- ‚úÖ Discoverability: Optimized for YouTube search and recommendations
- ‚úÖ Scalable: Ready for multi-channel workflows

**To disable SEO optimization:**
```bash
# In .env
SEO_ENABLED=false
```

## Project Structure

```
youtube-shorts-factory/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py              # CLI entry point
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ models.py            # Data models
‚îÇ   ‚îú‚îÄ‚îÄ workflow.py          # Main orchestrator
‚îÇ   ‚îî‚îÄ‚îÄ services/
‚îÇ       ‚îú‚îÄ‚îÄ reddit.py        # Reddit scraping
‚îÇ       ‚îú‚îÄ‚îÄ sheets.py        # Google Sheets
‚îÇ       ‚îú‚îÄ‚îÄ llm.py          # Gemini LLM
‚îÇ       ‚îú‚îÄ‚îÄ media.py        # Media server client
‚îÇ       ‚îú‚îÄ‚îÄ youtube.py      # YouTube upload
‚îÇ       ‚îî‚îÄ‚îÄ profile_manager.py  # Voice/music profiles
‚îú‚îÄ‚îÄ workflow_youtube_shorts/
‚îÇ   ‚îî‚îÄ‚îÄ workflow_motivational_shorts.json  # Original n8n workflow (reference)
‚îú‚îÄ‚îÄ profiles.yaml           # Voice & music profiles
‚îú‚îÄ‚îÄ pyproject.toml          # Dependencies
‚îú‚îÄ‚îÄ .env.example            # Environment template
‚îî‚îÄ‚îÄ README.md
```

## Workflow Details

### 1. Reddit Scraping

- Uses public JSON endpoints (no API authentication required)
- Fetches top posts from specified subreddit
- Filters by content length and type
- Saves to Google Sheets

### 2. Content Generation (Gemini)

- Creates motivational speech from story
- Splits into 5-8 scenes
- Generates image prompts for each scene

### 3. Media Generation

**Sequential Processing:**
- **Images**: Generated one at a time (Together.ai FLUX-Free requirement)
- **TTS**: Profile-based voice configuration from `profiles.yaml`
- **Videos**: Generated with captions as each TTS completes
- **Music**: Selected from profile playlist (random or sequential rotation)

### 4. Video Assembly

- Merges all scene videos
- Adds background music (optional)
- Applies transitions

### 5. YouTube Upload

- Downloads final video
- Uploads with metadata
- Updates Google Sheets

### 6. Cleanup

- Deletes temporary files from media server

## Advantages Over n8n

‚úÖ **Type Safety**: Full type hints and Pydantic validation
‚úÖ **Error Handling**: Robust retry logic with tenacity
‚úÖ **Async Performance**: Concurrent processing where possible
‚úÖ **Testing**: Easy to unit test individual services
‚úÖ **Customization**: Direct SDK access for fine-tuning
‚úÖ **Versioning**: Git-friendly Python code
‚úÖ **Debugging**: Better logging and error messages
‚úÖ **IDE Support**: Autocomplete and refactoring
‚úÖ **Performance**: GPU encoding support, optimized prompts
‚úÖ **Profile System**: Easy voice/music management with YAML configuration

## Troubleshooting

### Media Server Issues

```bash
# Check if server is running
python -m src.main check-server

# Check server logs
# (depends on your media server setup)
```

### Google OAuth Errors

- Delete `token.json` and `token_youtube.json`
- Run the workflow again to re-authenticate
- Ensure credentials.json is valid

### Rate Limits

- Together.ai: Free tier has limits, retries handled automatically
- Reddit: Public endpoints have rate limits (respectful delays recommended)
- YouTube: Daily upload quota (varies by account)

### TTS/Video Generation Timeouts

- Increase `MEDIA_PROCESSING_TIMEOUT` in .env
- Check media server resources (CPU/RAM/GPU)
- Try shorter scenes if timeout persists

## Development

### Run with uv

```bash
uv run python -m src.main --help
```

### Install dev dependencies

```bash
uv pip install -e ".[dev]"
```

### Code formatting

```bash
ruff check src/
ruff format src/
```

## Contributing

This is a personal project migrated from n8n. Feel free to fork and adapt to your needs, and if you do so,
don't you F!!!!kng dare to sell it. Give back to the community and you shall always find what you need.

## License

See LICENSE file.

## Credits

- Original n8n workflow, concept and project was/is from "ai agents az" and even though this developer actually DELETED the FOSS version project out of nowhere and now just sells the workflow on the well known `skool.com` where you can buy N8N workflows to backup your N8N nodes straight to github and YES with plain text json credentials included ü§£ü§£ü§£ü§£.
- Uses: Gemini, FLUX, Kokoro, Chatterbox, FFmpeg, Together.ai
- Built with: Python, uv, httpx, pydantic, rich and a LOT! ... A LOT !!!!!! of DEBUGGING. This thing is very fragile like a dandelion on the middle of florida.
- Resemble.ai/Chatterbox even though the actual python multilingual chatterbox documentation is the size of 10 sentences, the model is actually very very good. Even though the only way to make it to work is with python 3.10 and removing all torch ecosystem like 10 times, when it builds it's pure magic.

---

**Note**: This project requires a local media processing server. See the original n8n workflow for server setup details.
